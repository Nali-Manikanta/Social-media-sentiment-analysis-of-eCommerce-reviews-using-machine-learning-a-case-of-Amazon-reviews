# -*- coding: utf-8 -*-
"""Mani_amazon_reviews_sentiment_analysis-1-Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1298gK6AbtGpKqIyI772_6GVwWLNfa6bq

<!-- https://github.com/lcarcamo1526/Amazon-Reviews-Analysis -->
https://github.com/lcarcamo1526/Amazon-Reviews-Analysis/blob/master/amazon_alexa.tsv
"""

#General Imports
import numpy as np
import pandas as pd
import pickle 
from os.path import join

#Preprocessing related imports 
from nltk.stem import WordNetLemmatizer
import gensim.parsing.preprocessing as gpp
import gensim.utils as gu

import pandas as pd
import seaborn as sns
import numpy as np
import tensorflow_hub as hub
import tensorflow as tf
from gensim.models import Word2Vec
from sklearn.model_selection import train_test_split
import tensorflow_hub as hub
# import tensorflow_text as text
from gensim.models import Doc2Vec
from gensim.models.doc2vec import TaggedDocument

import string
import nltk
nltk.download('stopwords')
from nltk.sentiment.vader import SentimentIntensityAnalyzer as VS
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem.porter import *

import pandas as pd 
import matplotlib.pyplot as plt 
import numpy as np 
import tensorflow as tf 
import re 
from sklearn.feature_extraction.text import TfidfVectorizer
from tensorflow.keras.preprocessing.text import Tokenizer
import tensorflow as tf
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score
import seaborn as sns 
plt.style.use('ggplot')

"""# Data reading"""

df_train=pd.read_csv("/content/amazon_alexa.tsv",sep='\t')

df_train.info() # showing information about the data

df_train.head() # displaying the first 5 rows of the data

df_train['feedback'].value_counts() # value counts for feedback

df_train['rating'].value_counts() # value counts for ratings

"""# Exploratory data analysis and pre processing"""

sns.countplot(x ='rating', data = df_train)

def  processing_data(text): # preprocessing the data
  text=str(text)
  list_preprocess=[gpp.strip_tags, gpp.strip_punctuation, gpp.strip_multiple_whitespaces, gpp.strip_numeric, gpp.remove_stopwords, gpp.strip_short]
  for proc in list_preprocess:
    text=proc(text)  
  return text

df_train["verified_reviews"] = df_train["verified_reviews"].apply(processing_data)

df_train.head(10)

"""* tokenizing"""

rev_tokenized = df_train['verified_reviews'].apply(lambda x: x.split()) # tokenizing the tweets
print(rev_tokenized)

# import these modules
nltk.download('omw-1.4')
nltk.download('wordnet')
from nltk.stem import WordNetLemmatizer  
Lemmatizer = WordNetLemmatizer()

"""* lemmatizing"""

def Lemmatization(tweet):
  lemmatized_tweet = ' '.join([Lemmatizer.lemmatize(tw) for tw in tweet])
  return lemmatized_tweet

rev_lemmatized = rev_tokenized.apply(Lemmatization)
print(rev_lemmatized)

df_train['Processed_Reviews']= rev_lemmatized

df_train.sample(10)



"""* plotting word clouds"""

from wordcloud import WordCloud

rating_1 = ' '.join([text for text in df_train['Processed_Reviews'][df_train['rating'] == 1]])
wordcloud = WordCloud(width=900, height=500,random_state=34, max_font_size=110).generate(rating_1)
plt.figure(figsize=(12, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

rating_2 = ' '.join([text for text in df_train['Processed_Reviews'][df_train['rating'] == 2]])
wordcloud = WordCloud(width=900, height=500,random_state=34, max_font_size=110).generate(rating_2)
plt.figure(figsize=(12, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

rating_3 = ' '.join([text for text in df_train['Processed_Reviews'][df_train['rating'] == 3]])
wordcloud = WordCloud(width=900, height=500,random_state=34, max_font_size=110).generate(rating_3)
plt.figure(figsize=(12, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

rating_4 = ' '.join([text for text in df_train['Processed_Reviews'][df_train['rating'] == 4]])
wordcloud = WordCloud(width=900, height=500,random_state=34, max_font_size=110).generate(rating_4)
plt.figure(figsize=(12, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

rating_5 = ' '.join([text for text in df_train['Processed_Reviews'][df_train['rating'] == 5]])
wordcloud = WordCloud(width=900, height=500,random_state=34, max_font_size=110).generate(rating_5)
plt.figure(figsize=(12, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

"""* TFID VECTORIZING"""

#determining TF-IDF Features of the words in the dataset. 
TfId_vectorizer = TfidfVectorizer(ngram_range=(1, 2),max_df=0.75, min_df=5, max_features=10000)
tfidf = TfId_vectorizer.fit_transform(df_train['Processed_Reviews'] )

# tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=25, max_features=5000, use_idf=True)
# tfidf = tfidf_vectorizer.fit_transform(df_train["Processed_Reviews"])

print(tfidf)

"""# Model building

* testing and training data splitting
"""

X=tfidf #Tf_vector
y = df_train['rating'].astype(int)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import confusion_matrix, classification_report,f1_score,accuracy_score
# from sklearn.metrics import classification_
from sklearn.metrics import accuracy_score

"""* Gradient booster classifier"""

from sklearn.ensemble import GradientBoostingClassifier

model = GradientBoostingClassifier()
# model = LogisticRegression(random_state = 42)
model.fit(X_train, y_train)
accuracy = model.score(X_test, y_test)
acc_1=accuracy* 100
print(f"Accuracy of Gradient Bo0sting classifer {acc_1:.2f} %")
y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
print('  ')
print(report)

"""* Logistic regression classifier"""

model = LogisticRegression(multi_class='multinomial')
# model = LogisticRegression(random_state = 42)
model.fit(X_train, y_train)
accuracy = model.score(X_test, y_test)
acc_2=accuracy* 100
print(f"Accuracy of Logistic Regression {acc_2:.2f} %")
y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
print('  ')
print(report)

"""* Random forest classifier"""

model = RandomForestClassifier(random_state = 42)
model.fit(X_train, y_train)
accuracy = model.score(X_test, y_test)
acc_3=accuracy* 100
print(f"Accuracy of Logistic Regression {acc_3:.2f} %")
y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
print('  ')
print(report)

"""* Linear support vector classifier"""

from sklearn.svm import LinearSVC

model = LinearSVC()
model.fit(X_train, y_train)
acc = model.score(X_test, y_test)
acc_4=acc* 100
print(f"Accuracy of Support vector classifier {acc_4:.2f} %")
y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
print('  ')
print(report)

"""* Multinomial naive bayes classifier"""

from sklearn.naive_bayes import MultinomialNB

model = MultinomialNB()
model.fit(X_train, y_train)
acc = model.score(X_test, y_test)
acc_5=acc* 100
print(f"Accuracy of Multinomial Naive Bayes {acc_5:.2f} %")
y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
print('  ')
print(report)



print(f"The accuracy of Gradient boosting classifier is {acc_1:.2f} %")
print(f"The accuracy of Logistic Regression is {acc_2:.2f} %")
print(f"The accuracy of Random Forest classifier is {acc_3:.2f} %")
print(f"The accuracy of Linear SVC is {acc_4:.2f} %")
print(f"The accuracy of Multinomial naive bayes classifier is {acc_5:.2f} %")

"""* Random forest is the best classifier for this data."""